"""
Streamlit Web Application for S&P 500 Rolling Returns and Convergence Analysis
"""

import streamlit as st
import pandas as pd
import numpy as np
from typing import Dict, List, Any
import traceback

# Import custom modules
from data_processor import DataProcessor
from ui_components import (
    apply_custom_css, create_header, create_sidebar_config,
    display_data_summary, create_returns_timeline_chart,
    create_rolling_cagr_chart, create_window_comparison_chart,
    create_convergence_heatmap, create_no_loss_chart,
    display_analysis_table, create_download_section,
    show_info_message, create_metric_cards, generate_summary_report,
    create_professional_report_section
)
from config import APP_TITLE, MESSAGES, FOOTER_TEXT


# Page configuration
st.set_page_config(
    page_title=APP_TITLE,
    page_icon="ğŸ“ˆ",
    layout="wide",
    initial_sidebar_state="expanded"
)




def initialize_session_state():
    """Initialize session state variables."""
    if 'data_processor' not in st.session_state:
        st.session_state.data_processor = DataProcessor()
    
    if 'analysis_results' not in st.session_state:
        st.session_state.analysis_results = {}
    
    if 'data_loaded' not in st.session_state:
        st.session_state.data_loaded = False

    # é»˜è®¤è¯­è¨€ï¼šä¸­æ–‡ï¼ˆéåŒè¯­ï¼‰
    if 'bi_lang' not in st.session_state:
        st.session_state.bi_lang = False


def load_data(config: Dict[str, Any]) -> bool:
    """Load data based on configuration."""
    processor = st.session_state.data_processor
    
    try:
        if config['data_source'] == "ä»SlickChartsä¸‹è½½":
            data = processor.download_slickcharts_data()
        else:
            if config['uploaded_file'] is not None:
                data = processor.load_csv_data(config['uploaded_file'])
            else:
                st.warning("è¯·ä¸Šä¼ CSVæ–‡ä»¶")
                return False
        
        if data is not None:
            success = processor.set_data(data)
            if success:
                st.session_state.data_loaded = True
                return True
    
    except Exception as e:
        st.error(f"æ•°æ®åŠ è½½å¤±è´¥: {str(e)}")
        st.error(traceback.format_exc())
    
    return False


def run_analysis(config: Dict[str, Any]):
    """Run the complete analysis."""
    if not st.session_state.data_loaded:
        st.warning("è¯·å…ˆåŠ è½½æ•°æ®")
        return
    
    processor = st.session_state.data_processor
    
    try:
        with st.spinner("æ­£åœ¨è¿›è¡Œåˆ†æ..."):
            # Get data hash for cache invalidation
            data_hash = processor.get_data_hash()

            # Compute rolling analysis
            rolling_results = processor.compute_rolling_analysis(
                config['start_years'],
                config['windows'],
                data_hash
            )

            # Compute no-loss analysis
            no_loss_results = processor.compute_no_loss_analysis(
                config['start_years'],
                data_hash
            )

            # Compute convergence analysis
            convergence_results = processor.compute_convergence_analysis(
                config['start_years'],
                config['thresholds'],
                data_hash
            )

            # Compute risk metrics analysis
            risk_metrics_results = processor.compute_risk_metrics_analysis(
                config['start_years'],
                config['windows'],
                data_hash
            )

            # Store results in session state
            st.session_state.analysis_results = {
                'rolling': rolling_results,
                'no_loss': no_loss_results,
                'convergence': convergence_results,
                'risk_metrics': risk_metrics_results,
                'config': config
            }
            
            st.success(MESSAGES['analysis_complete'])
    
    except Exception as e:
        st.error(f"åˆ†æå¤±è´¥: {str(e)}")
        st.error(traceback.format_exc())


def display_data_overview():
    """Display data overview tab."""
    processor = st.session_state.data_processor
    
    if not st.session_state.data_loaded:
        show_info_message("è¯·å…ˆåœ¨ä¾§è¾¹æ é…ç½®æ•°æ®æºå¹¶åŠ è½½æ•°æ®", "info")
        return
    
    # Display data summary
    summary = processor.get_data_summary()
    display_data_summary(summary)
    
    # Display returns timeline chart
    st.subheader("ğŸ“Š å†å¹´æ”¶ç›Šç‡æ—¶é—´çº¿")
    timeline_chart = create_returns_timeline_chart(processor.data)
    st.plotly_chart(timeline_chart, use_container_width=True)
    
    # Display raw data table
    st.subheader("ğŸ“‹ åŸå§‹æ•°æ®")
    st.dataframe(
        processor.data,
        use_container_width=True,
        height=400
    )


def display_rolling_analysis():
    """Display rolling CAGR analysis tab."""
    if 'rolling' not in st.session_state.analysis_results:
        show_info_message("è¯·å…ˆè¿è¡Œåˆ†æ", "info")
        return
    
    rolling_results = st.session_state.analysis_results['rolling']
    config = st.session_state.analysis_results['config']
    
    # Display charts for each start year
    for start_year in config['start_years']:
        st.subheader(f"ğŸ“ˆ èµ·å§‹å¹´ä»½: {start_year}")
        
        # Rolling CAGR chart
        chart = create_rolling_cagr_chart(rolling_results, start_year)
        if chart:
            st.plotly_chart(chart, use_container_width=True)
        
        # Summary table
        processor = st.session_state.data_processor
        summary_df = processor.create_summary_dataframe(rolling_results, start_year)
        
        if not summary_df.empty:
            format_cols = {
                'best_cagr': 'percentage',
                'worst_cagr': 'percentage',
                'avg_cagr': 'percentage',
                'std_cagr': 'percentage',
                'p10_cagr': 'percentage',
                'median_cagr': 'percentage',
                'p90_cagr': 'percentage',
                'stability_index': 'decimal',
                'variation_coeff': 'decimal'
            }
            display_analysis_table(summary_df, f"çª—å£ç»Ÿè®¡æ‘˜è¦ - {start_year}", format_cols)
        
        st.divider()
    
    # Window comparison chart
    st.subheader("ğŸ“Š æ—¶é—´çª—å£æ¯”è¾ƒ")
    comparison_chart = create_window_comparison_chart(rolling_results, config['start_years'])
    st.plotly_chart(comparison_chart, use_container_width=True)


def display_no_loss_analysis():
    """Display no-loss analysis tab."""
    if 'no_loss' not in st.session_state.analysis_results:
        show_info_message("è¯·å…ˆè¿è¡Œåˆ†æ", "info")
        return
    
    no_loss_results = st.session_state.analysis_results['no_loss']
    
    # Display chart
    chart = create_no_loss_chart(no_loss_results)
    if chart:
        st.plotly_chart(chart, use_container_width=True)
    
    # Display detailed table
    if no_loss_results:
        data_rows = []
        for start_year, result in no_loss_results.items():
            data_rows.append({
                'èµ·å§‹å¹´ä»½': start_year,
                'æœ€å°æŒæœ‰æœŸ': result['min_holding_years'],
                'æœ€å·®çª—å£': result['worst_window'],
                'æœ€å·®CAGR': result['worst_cagr'],
                'æœ€ä½³çª—å£': result['best_window'],
                'æœ€ä½³CAGR': result['best_cagr'],
                'å¹³å‡CAGR': result['average_cagr'],
                'æ£€æŸ¥çª—å£æ•°': result['num_windows_checked']
            })
        
        df = pd.DataFrame(data_rows)
        format_cols = {
            'æœ€å·®CAGR': 'percentage',
            'æœ€ä½³CAGR': 'percentage',
            'å¹³å‡CAGR': 'percentage'
        }
        display_analysis_table(df, "æ— æŸå¤±æŒæœ‰æœŸè¯¦ç»†åˆ†æ", format_cols)


def display_convergence_analysis():
    """Display convergence analysis tab."""
    if 'convergence' not in st.session_state.analysis_results:
        show_info_message("è¯·å…ˆè¿è¡Œåˆ†æ", "info")
        return
    
    convergence_results = st.session_state.analysis_results['convergence']
    config = st.session_state.analysis_results['config']
    
    # Display heatmap
    st.subheader("ğŸ”¥ æ”¶æ•›æ€§çƒ­åŠ›å›¾")
    heatmap = create_convergence_heatmap(
        convergence_results,
        config['start_years'],
        config['thresholds']
    )
    st.plotly_chart(heatmap, use_container_width=True)

    # AI-like summary report (local heuristic)
    with st.expander("ğŸ§  ç”Ÿæˆç»¼åˆæ™ºèƒ½æ€»ç»“ï¼ˆæ»šåŠ¨ + æ— æŸå¤± + æ”¶æ•›ï¼‰", expanded=False):
        target_thr = st.select_slider(
            "é€‰æ‹©ç›®æ ‡æ”¶æ•›é˜ˆå€¼ï¼ˆç”¨äºå»ºè®®æœ€çŸ­æŒæœ‰æœŸï¼‰",
            options=[f"{t:.2%}" for t in config['thresholds']] if config.get('thresholds') else ["0.50%"],
            value=(f"{config['thresholds'][len(config['thresholds'])//2]:.2%}" if config.get('thresholds') else "0.50%")
        )
        granularity = st.radio("æŠ¥å‘Šç²’åº¦ / Report granularity", ["ç®€ç‰ˆ", "æ ‡å‡†", "è¯¦ç»†"], index=1, horizontal=True)
        bi = st.toggle("ä¸­è‹±åŒè¯­ / Bilingual", value=st.session_state.get("bi_lang", False), key="bi_lang")
        col_a, col_b = st.columns([1, 1])
        with col_a:
            gen_clicked = st.button("âœ¨ ç”Ÿæˆ/æ›´æ–°æ€»ç»“", key="gen_report")
        with col_b:
            if st.button("ğŸ—‘ï¸ æ¸…é™¤æŠ¥å‘Š", key="clear_report"):
                st.session_state.pop('ai_report_md', None)
        if gen_clicked:
            # å°†é€‰æ‹©çš„å­—ç¬¦ä¸²é˜ˆå€¼è½¬ä¸ºå°æ•°
            try:
                thr = float(target_thr.strip('%'))/100.0
            except Exception:
                thr = None
            depth_map = {"ç®€ç‰ˆ": "brief", "æ ‡å‡†": "standard", "è¯¦ç»†": "detailed"}
            report_md = generate_summary_report(
                st.session_state.analysis_results['rolling'],
                st.session_state.analysis_results['no_loss'],
                st.session_state.analysis_results['convergence'],
                config,
                target_threshold=thr,
                language='bi' if st.session_state.get("bi_lang", True) else 'zh',
                depth=depth_map.get(granularity, 'standard')
            )
            st.session_state['ai_report_md'] = report_md
        # å§‹ç»ˆå±•ç¤ºå·²ç”Ÿæˆçš„æŠ¥å‘Šä¸ä¸‹è½½åŒºï¼ˆå¦‚æœ‰ï¼‰
        if 'ai_report_md' in st.session_state and st.session_state['ai_report_md']:
            st.markdown(st.session_state['ai_report_md'])
            create_download_section({'ai_report_md': st.session_state['ai_report_md']}, filename_prefix="sp500_ai_summary")

    # Display detailed table
    data_rows = []
    for start_year in config['start_years']:
        if start_year in convergence_results:
            for threshold in config['thresholds']:
                if threshold in convergence_results[start_year]:
                    result = convergence_results[start_year][threshold]
                    data_rows.append({
                        'èµ·å§‹å¹´ä»½': start_year,
                        'é˜ˆå€¼': threshold,
                        'æœ€å°æŒæœ‰æœŸ': result['min_holding_years'],
                        'æœ€ä½³çª—å£': result['best_window'],
                        'æœ€ä½³CAGR': result['best_cagr'],
                        'æœ€å·®çª—å£': result['worst_window'],
                        'æœ€å·®CAGR': result['worst_cagr'],
                        'æ”¶ç›Šå·®': result['spread']
                    })
    
    if data_rows:
        df = pd.DataFrame(data_rows)
        format_cols = {
            'é˜ˆå€¼': 'percentage',
            'æœ€ä½³CAGR': 'percentage',
            'æœ€å·®CAGR': 'percentage',
            'æ”¶ç›Šå·®': 'decimal'
        }
        display_analysis_table(df, "æ”¶æ•›æ€§åˆ†æè¯¦ç»†ç»“æœ", format_cols)


def display_risk_metrics_analysis():
    """Display risk metrics analysis tab."""
    if not st.session_state.analysis_results or 'risk_metrics' not in st.session_state.analysis_results:
        show_info_message("è¯·å…ˆè¿è¡Œåˆ†æä»¥æŸ¥çœ‹é£é™©æŒ‡æ ‡ç»“æœ", "info")
        return

    risk_results = st.session_state.analysis_results['risk_metrics']
    config = st.session_state.analysis_results['config']

    st.subheader("âš ï¸ é£é™©æŒ‡æ ‡åˆ†æç»“æœ")

    # Display overall risk metrics for each start year
    st.subheader("ğŸ“Š æ•´ä½“é£é™©æŒ‡æ ‡")

    # Create metric cards for overall statistics
    overall_metrics = {}
    for start_year, year_data in risk_results.items():
        if 'overall' in year_data and year_data['overall']:
            metrics = year_data['overall']
            overall_metrics[f"{start_year}å¹´èµ·"] = {
                'CAGR': f"{metrics.get('cagr', 0):.2%}",
                'å¤æ™®æ¯”ç‡': f"{metrics.get('sharpe_ratio', 0):.2f}",
                'æœ€å¤§å›æ’¤': f"{metrics.get('max_drawdown', 0):.2%}",
                'æ³¢åŠ¨ç‡': f"{metrics.get('volatility', 0):.2%}"
            }

    if overall_metrics:
        # Display metrics in columns
        cols = st.columns(len(overall_metrics))
        for i, (period, metrics) in enumerate(overall_metrics.items()):
            with cols[i]:
                st.markdown(f"**{period}**")
                for metric, value in metrics.items():
                    st.metric(metric, value)

    # Display detailed risk metrics table
    st.subheader("ğŸ“‹ è¯¦ç»†é£é™©æŒ‡æ ‡")

    # Prepare data for detailed table
    detailed_data = []
    for start_year, year_data in risk_results.items():
        if 'overall' in year_data and year_data['overall']:
            metrics = year_data['overall']
            detailed_data.append({
                'èµ·å§‹å¹´ä»½': start_year,
                'æœŸé—´': f"{metrics.get('start_year', '')}-{metrics.get('end_year', '')}",
                'CAGR': f"{metrics.get('cagr', 0):.2%}",
                'å¤æ™®æ¯”ç‡': f"{metrics.get('sharpe_ratio', 0):.3f}",
                'ç´¢æè¯ºæ¯”ç‡': f"{metrics.get('sortino_ratio', 0):.3f}",
                'Calmaræ¯”ç‡': f"{metrics.get('calmar_ratio', 0):.3f}",
                'æ³¢åŠ¨ç‡': f"{metrics.get('volatility', 0):.2%}",
                'æœ€å¤§å›æ’¤': f"{metrics.get('max_drawdown', 0):.2%}",
                'VaR(95%)': f"{metrics.get('var_95', 0):.2%}",
                'CVaR(95%)': f"{metrics.get('cvar_95', 0):.2%}"
            })

    if detailed_data:
        df = pd.DataFrame(detailed_data)
        st.dataframe(df, use_container_width=True, height=300)


def display_multi_asset_analysis():
    """Display multi-asset analysis tab."""
    st.subheader("ğŸŒ å¤šèµ„äº§ç±»åˆ«æ¯”è¾ƒåˆ†æ")

    if not st.session_state.data_loaded:
        show_info_message("è¯·å…ˆåŠ è½½S&P 500æ•°æ®ä½œä¸ºåŸºå‡†", "info")
        return

    # Asset selection section
    st.subheader("ğŸ“‹ èµ„äº§é€‰æ‹©")

    # Get available assets
    processor = st.session_state.data_processor
    available_assets = processor.get_available_assets()

    # Create asset selection interface
    selected_assets = []

    # Always include S&P 500 as benchmark
    selected_assets.append('SPY')
    st.info("ğŸ“Œ S&P 500 (SPY) å·²è‡ªåŠ¨é€‰æ‹©ä½œä¸ºåŸºå‡†")

    # Asset class selection
    for asset_class, assets in available_assets.items():
        if asset_class == 'equity' and any(asset['symbol'] == 'SPY' for asset in assets):
            # Skip SPY in equity section since it's already selected
            other_equity_assets = [asset for asset in assets if asset['symbol'] != 'SPY']
            if other_equity_assets:
                st.markdown(f"**{asset_class.upper()} è‚¡ç¥¨æŒ‡æ•°**")
                for asset in other_equity_assets:
                    if st.checkbox(f"{asset['name']} ({asset['symbol']})",
                                 help=f"{asset['description']} | èµ·å§‹å¹´ä»½: {asset['inception_year']}",
                                 key=f"asset_{asset['symbol']}"):
                        selected_assets.append(asset['symbol'])
        else:
            st.markdown(f"**{asset_class.upper()}**")
            for asset in assets:
                if st.checkbox(f"{asset['name']} ({asset['symbol']})",
                             help=f"{asset['description']} | èµ·å§‹å¹´ä»½: {asset['inception_year']}",
                             key=f"asset_{asset['symbol']}"):
                    selected_assets.append(asset['symbol'])

    if len(selected_assets) < 2:
        st.warning("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªé¢å¤–èµ„äº§è¿›è¡Œæ¯”è¾ƒåˆ†æ")
        return

    # Analysis period selection
    st.subheader("ğŸ“… åˆ†ææœŸé—´")
    col1, col2 = st.columns(2)

    with col1:
        start_year = st.selectbox("èµ·å§‹å¹´ä»½",
                                options=[1990, 2000, 2010, 2015, 2020],
                                index=0,
                                key="multi_asset_start_year")

    with col2:
        end_year = st.selectbox("ç»“æŸå¹´ä»½",
                              options=[2020, 2021, 2022, 2023],
                              index=3,
                              key="multi_asset_end_year")

    # Run analysis button
    if st.button("ğŸš€ è¿è¡Œå¤šèµ„äº§åˆ†æ", use_container_width=True):
        try:
            # Set selected assets
            processor.set_selected_assets(selected_assets)

            # Run analysis
            with st.spinner("æ­£åœ¨è¿›è¡Œå¤šèµ„äº§åˆ†æ..."):
                multi_asset_results = processor.compute_multi_asset_analysis(start_year, end_year)

            # Store results
            st.session_state.multi_asset_results = multi_asset_results
            st.session_state.multi_asset_config = {
                'selected_assets': selected_assets,
                'start_year': start_year,
                'end_year': end_year
            }

            st.success("âœ… å¤šèµ„äº§åˆ†æå®Œæˆï¼")

        except Exception as e:
            st.error(f"å¤šèµ„äº§åˆ†æå¤±è´¥: {str(e)}")
            return

    # Display results if available
    if hasattr(st.session_state, 'multi_asset_results') and st.session_state.multi_asset_results:
        display_multi_asset_results()


def display_multi_asset_results():
    """Display multi-asset analysis results."""
    results = st.session_state.multi_asset_results
    config = st.session_state.multi_asset_config

    st.markdown("---")
    st.subheader("ğŸ“Š åˆ†æç»“æœ")

    # Individual asset performance
    st.subheader("ğŸ¯ ä¸ªåˆ«èµ„äº§è¡¨ç°")

    # Create performance comparison table
    performance_data = []
    for symbol, asset_data in results['individual_assets'].items():
        asset_info = asset_data['asset_info']
        metrics = asset_data['risk_metrics']

        performance_data.append({
            'èµ„äº§': f"{asset_info['name']} ({symbol})",
            'èµ„äº§ç±»åˆ«': asset_info['asset_class'],
            'CAGR': f"{metrics.get('cagr', 0):.2%}",
            'å¤æ™®æ¯”ç‡': f"{metrics.get('sharpe_ratio', 0):.3f}",
            'æœ€å¤§å›æ’¤': f"{metrics.get('max_drawdown', 0):.2%}",
            'æ³¢åŠ¨ç‡': f"{metrics.get('volatility', 0):.2%}"
        })

    if performance_data:
        df = pd.DataFrame(performance_data)
        st.dataframe(df, use_container_width=True, height=300)

    # Correlation analysis
    if 'correlation_matrix' in results:
        st.subheader("ğŸ”— ç›¸å…³æ€§åˆ†æ")

        correlation_matrix = results['correlation_matrix']

        # Create correlation heatmap
        import plotly.graph_objects as go

        fig = go.Figure(data=go.Heatmap(
            z=correlation_matrix.values,
            x=correlation_matrix.columns,
            y=correlation_matrix.index,
            colorscale='RdBu',
            zmid=0,
            text=correlation_matrix.round(3).values,
            texttemplate="%{text}",
            textfont={"size": 10},
            hoverongaps=False
        ))

        fig.update_layout(
            title="èµ„äº§ç›¸å…³æ€§çŸ©é˜µ",
            xaxis_title="èµ„äº§",
            yaxis_title="èµ„äº§",
            height=500,
            margin=dict(l=80, r=80, t=80, b=80)
        )

        st.plotly_chart(fig, use_container_width=True)

        # Correlation insights
        st.markdown("**ç›¸å…³æ€§æ´å¯Ÿï¼š**")

        # Find highest and lowest correlations
        corr_values = []
        for i in range(len(correlation_matrix.columns)):
            for j in range(i+1, len(correlation_matrix.columns)):
                asset1 = correlation_matrix.columns[i]
                asset2 = correlation_matrix.columns[j]
                corr = correlation_matrix.iloc[i, j]
                corr_values.append((asset1, asset2, corr))

        # Sort by correlation
        corr_values.sort(key=lambda x: abs(x[2]), reverse=True)

        if corr_values:
            highest_corr = corr_values[0]
            lowest_corr = min(corr_values, key=lambda x: x[2])

            st.write(f"â€¢ æœ€é«˜ç›¸å…³æ€§: {highest_corr[0]} ä¸ {highest_corr[1]} ({highest_corr[2]:.3f})")
            st.write(f"â€¢ æœ€ä½ç›¸å…³æ€§: {lowest_corr[0]} ä¸ {lowest_corr[1]} ({lowest_corr[2]:.3f})")

    # Asset class summary
    if 'asset_class_summary' in results:
        st.subheader("ğŸ“ˆ èµ„äº§ç±»åˆ«æ±‡æ€»")

        asset_class_data = []
        for asset_class, class_data in results['asset_class_summary'].items():
            avg_metrics = class_data['average_metrics']
            asset_class_data.append({
                'èµ„äº§ç±»åˆ«': asset_class.upper(),
                'èµ„äº§æ•°é‡': class_data['count'],
                'å¹³å‡CAGR': f"{avg_metrics.get('cagr', 0):.2%}",
                'å¹³å‡å¤æ™®æ¯”ç‡': f"{avg_metrics.get('sharpe_ratio', 0):.3f}",
                'å¹³å‡æœ€å¤§å›æ’¤': f"{avg_metrics.get('max_drawdown', 0):.2%}",
                'å¹³å‡æ³¢åŠ¨ç‡': f"{avg_metrics.get('volatility', 0):.2%}"
            })

        if asset_class_data:
            df = pd.DataFrame(asset_class_data)
            st.dataframe(df, use_container_width=True)

    # Efficient frontier
    if 'efficient_frontier' in results:
        st.subheader("ğŸ“Š æœ‰æ•ˆå‰æ²¿")

        frontier_data = results['efficient_frontier']

        # Create efficient frontier chart
        fig = go.Figure()

        # Add scatter plot of portfolios
        fig.add_trace(go.Scatter(
            x=frontier_data['volatility'],
            y=frontier_data['returns'],
            mode='markers',
            marker=dict(
                size=6,
                color=frontier_data['sharpe_ratio'],
                colorscale='Viridis',
                showscale=True,
                colorbar=dict(
                    title="å¤æ™®æ¯”ç‡",
                    x=1.02,
                    len=0.8,
                    thickness=15
                )
            ),
            text=[f"å¤æ™®æ¯”ç‡: {sr:.3f}" for sr in frontier_data['sharpe_ratio']],
            hovertemplate="æ”¶ç›Šç‡: %{y:.2%}<br>æ³¢åŠ¨ç‡: %{x:.2%}<br>%{text}<extra></extra>",
            name="æŠ•èµ„ç»„åˆ"
        ))

        # Find and highlight optimal portfolio (highest Sharpe ratio)
        max_sharpe_idx = np.argmax(frontier_data['sharpe_ratio'])
        fig.add_trace(go.Scatter(
            x=[frontier_data['volatility'][max_sharpe_idx]],
            y=[frontier_data['returns'][max_sharpe_idx]],
            mode='markers',
            marker=dict(size=15, color='red', symbol='star'),
            name="æœ€ä¼˜æŠ•èµ„ç»„åˆ",
            hovertemplate="æœ€ä¼˜ç»„åˆ<br>æ”¶ç›Šç‡: %{y:.2%}<br>æ³¢åŠ¨ç‡: %{x:.2%}<extra></extra>"
        ))

        fig.update_layout(
            title="æœ‰æ•ˆå‰æ²¿åˆ†æ",
            xaxis_title="æ³¢åŠ¨ç‡ (å¹´åŒ–)",
            yaxis_title="é¢„æœŸæ”¶ç›Šç‡ (å¹´åŒ–)",
            height=500,
            margin=dict(l=60, r=120, t=80, b=60),
            showlegend=True,
            legend=dict(
                x=1.02,
                y=0.5,
                xanchor="left",
                yanchor="middle"
            )
        )

        st.plotly_chart(fig, use_container_width=True)

        # Show optimal portfolio weights
        optimal_weights = frontier_data['weights'][max_sharpe_idx]
        st.markdown("**æœ€ä¼˜æŠ•èµ„ç»„åˆæƒé‡ï¼š**")

        weights_data = []
        for i, symbol in enumerate(config['selected_assets']):
            asset_name = results['individual_assets'][symbol]['asset_info']['name']
            weight = optimal_weights[i]
            weights_data.append({
                'èµ„äº§': f"{asset_name} ({symbol})",
                'æƒé‡': f"{weight:.1%}"
            })

        weights_df = pd.DataFrame(weights_data)
        st.dataframe(weights_df, use_container_width=True, hide_index=True)


def main():
    """Main application function."""
    try:
        # Initialize session state
        initialize_session_state()

        # Apply custom CSS
        apply_custom_css()

        # Create header
        create_header()
    except Exception as e:
        st.error(f"åº”ç”¨åˆå§‹åŒ–å¤±è´¥: {e}")
        st.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
        return

    # ç¯å¢ƒè‡ªæ£€ï¼ˆé»˜è®¤éšè—ï¼›å½“ SHOW_ENV_CHECK=true æ—¶æ˜¾ç¤ºï¼›æ²¡æœ‰ secrets.toml æ—¶å¿½ç•¥ï¼‰
    show_env_check = False
    try:
        # å®‰å…¨åœ°æ£€æŸ¥ secrets é…ç½®ï¼Œé¿å… StreamlitSecretNotFoundError
        import streamlit.runtime.secrets as secrets_module
        if hasattr(secrets_module, '_secrets') and secrets_module._secrets is not None:
            show_env_check = bool(st.secrets.get("SHOW_ENV_CHECK", False))
    except (ImportError, AttributeError, Exception):
        # åœ¨æ²¡æœ‰ secrets æ–‡ä»¶æˆ–å…¶ä»–é”™è¯¯æ—¶ï¼Œé»˜è®¤ä¸æ˜¾ç¤ºç¯å¢ƒæ£€æŸ¥
        show_env_check = False

    if show_env_check:
        try:
            import reportlab  # type: ignore
            st.sidebar.success("PDF ç»„ä»¶ï¼šreportlab å¯ç”¨")
        except Exception:
            st.sidebar.warning(
                "PDF ç»„ä»¶ä¸å¯ç”¨ï¼šæœªå®‰è£… reportlab æˆ–ç½‘ç»œé˜»æ–­ã€‚\n\n"
                "å®‰è£…å»ºè®®ï¼š\n"
                "1) pip install -i https://pypi.tuna.tsinghua.edu.cn/simple reportlab==3.6.13\n"
                "2) pip install --upgrade pip certifi setuptools wheel && pip install reportlab==3.6.13\n"
            )

    # Create sidebar configuration
    config = create_sidebar_config()

    # Check if configuration has changed
    config_changed = False
    if 'last_config' in st.session_state:
        if st.session_state.last_config != config:
            config_changed = True
            st.session_state.last_config = config
    else:
        st.session_state.last_config = config

    # If config changed and we have analysis results, show warning
    if config_changed and st.session_state.analysis_results:
        st.warning("âš ï¸ åˆ†æå‚æ•°å·²æ›´æ”¹ï¼Œè¯·é‡æ–°è¿è¡Œåˆ†æä»¥è·å–æœ€æ–°ç»“æœ")

    # Main content area
    col1, col2 = st.columns([3, 1])
    
    with col2:
        st.subheader("ğŸ›ï¸ æ“ä½œé¢æ¿")
        
        # Load data button
        if st.button("ğŸ“¥ åŠ è½½æ•°æ®", use_container_width=True):
            load_data(config)
        
        # Run analysis button
        if st.button("ğŸš€ è¿è¡Œåˆ†æ", use_container_width=True, disabled=not st.session_state.data_loaded):
            run_analysis(config)

        # Force re-analysis button (clears cache)
        if st.button("ğŸ”„ å¼ºåˆ¶é‡æ–°åˆ†æ", use_container_width=True, disabled=not st.session_state.data_loaded):
            st.cache_data.clear()  # Clear all cached data
            run_analysis(config)

        # Clear results button
        if st.button("ğŸ—‘ï¸æ¸…é™¤ç»“æœ", use_container_width=True):
            st.session_state.analysis_results = {}
            st.session_state.data_loaded = False
            st.cache_data.clear()
            st.rerun()
    
    with col1:
        # Create tabs for different views
        tab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs([
            "ğŸ“Š æ•°æ®æ¦‚è§ˆ",
            "ğŸ“ˆ æ»šåŠ¨åˆ†æ",
            "ğŸ›¡ï¸ æ— æŸå¤±åˆ†æ",
            "ğŸ¯ æ”¶æ•›æ€§åˆ†æ",
            "âš ï¸ é£é™©æŒ‡æ ‡",
            "ğŸŒ å¤šèµ„äº§åˆ†æ",
            "ğŸ›ï¸ GIPSåˆè§„æ€§"
        ])
        
        with tab1:
            display_data_overview()
        
        with tab2:
            display_rolling_analysis()
        
        with tab3:
            display_no_loss_analysis()
        
        with tab4:
            display_convergence_analysis()

        with tab5:
            display_risk_metrics_analysis()

            # Professional report generation section
            if st.session_state.data_loaded and st.session_state.analysis_results:
                st.markdown("---")
                create_professional_report_section(st.session_state.data_processor)

        with tab6:
            display_multi_asset_analysis()

        with tab7:
            display_gips_compliance_analysis()

            # æœ¯è¯­è¡¨ä¸‹è½½åŒº
            with st.expander("ğŸ“š æœ¯è¯­è¡¨ / Glossary", expanded=False):
                try:
                    from glossary import render_glossary_md, to_csv
                    md = render_glossary_md()
                    st.markdown(md)
                    # ä¸‹è½½æŒ‰é’®ï¼ˆCSV / Markdown / PDFï¼‰
                    import io
                    st.download_button(
                        label="ä¸‹è½½æœ¯è¯­è¡¨ CSV",
                        data=to_csv(),
                        file_name="glossary.csv",
                        mime="text/csv"
                    )
                    st.download_button(
                        label="ä¸‹è½½æœ¯è¯­è¡¨ Markdown",
                        data=md,
                        file_name="glossary.md",
                        mime="text/markdown"
                    )
                    # PDF å¯¼å‡ºï¼ˆåŸºç¡€æ–‡æœ¬ï¼‰
                    try:
                        from pdf_utils import render_plain_text_to_pdf
                        plain = md.replace('#','').replace('*','').replace('`','')
                        pdf_data = render_plain_text_to_pdf(
                            plain,
                            title="S&P 500 Analysis - Glossary",
                            footer="Generated by S&P 500 Analysis UI",
                            color_hex="#0B3B5A",
                        )
                        st.download_button(
                            label="ä¸‹è½½æœ¯è¯­è¡¨ PDF",
                            data=pdf_data,
                            file_name="glossary.pdf",
                            mime="application/pdf"
                        )
                    except Exception as e:
                        st.caption(f"æœ¯è¯­è¡¨PDFå¯¼å‡ºä¸å¯ç”¨: {e}")
                except Exception as e:
                    st.caption(f"æ— æ³•åŠ è½½æœ¯è¯­è¡¨: {e}")

    # Footer
    st.markdown(
        "<hr style='margin:2rem 0; opacity:0.2' />"
        f"<div style='text-align:center; color:#6B7280; font-size:12px;'>"
        f"{FOOTER_TEXT}"
        "</div>",
        unsafe_allow_html=True,
    )


def display_gips_compliance_analysis():
    """Display GIPS compliance analysis interface."""
    st.header("ğŸ›ï¸ GIPSåˆè§„æ€§åˆ†æ")
    st.markdown("""
    **å…¨çƒæŠ•èµ„è¡¨ç°æ ‡å‡† (GIPS) åˆè§„æ€§åˆ†æ**

    GIPSæ ‡å‡†ç¡®ä¿æŠ•èµ„è¡¨ç°ç»“æœçš„å…¬å¹³è¡¨è¿°å’Œå®Œæ•´æŠ«éœ²ï¼Œä¸ºæ½œåœ¨å®¢æˆ·å’Œé¡¾é—®æä¾›æ ‡å‡†åŒ–çš„è¡¨ç°è¡¡é‡æ–¹æ³•ã€‚
    """)

    # Initialize session state if needed
    if 'data_loaded' not in st.session_state:
        st.session_state.data_loaded = False
    if 'data_processor' not in st.session_state:
        st.session_state.data_processor = DataProcessor()

    if not st.session_state.data_loaded:
        st.warning("âš ï¸ è¯·å…ˆåœ¨æ•°æ®æ¦‚è§ˆæ ‡ç­¾é¡µä¸­åŠ è½½S&P 500æ•°æ®")
        return

    # Configuration section
    st.subheader("ğŸ“‹ åˆ†æé…ç½®")

    col1, col2 = st.columns(2)

    with col1:
        firm_name = st.text_input(
            "æŠ•èµ„å…¬å¸åç§°",
            value="Sample Investment Firm",
            help="è¾“å…¥è¿›è¡ŒGIPSåˆè§„æ€§åˆ†æçš„æŠ•èµ„å…¬å¸åç§°",
            key="gips_firm_name"
        )

        composite_name = st.text_input(
            "æŠ•èµ„ç»„åˆåç§°",
            value="S&P 500 Tracking Composite",
            help="è¾“å…¥æŠ•èµ„ç»„åˆæˆ–ç­–ç•¥çš„åç§°",
            key="gips_composite_name"
        )

    with col2:
        benchmark_options = {
            "SPY": "SPDR S&P 500 ETF",
            "QQQ": "Invesco QQQ Trust",
            "IWM": "iShares Russell 2000 ETF"
        }

        benchmark_symbol = st.selectbox(
            "åŸºå‡†æŒ‡æ•°",
            options=list(benchmark_options.keys()),
            format_func=lambda x: f"{x} - {benchmark_options[x]}",
            help="é€‰æ‹©ç”¨äºæ¯”è¾ƒçš„åŸºå‡†æŒ‡æ•°",
            key="gips_benchmark_symbol"
        )

        # Analysis period
        if st.session_state.data_processor and st.session_state.data_processor.data is not None:
            available_years = sorted(st.session_state.data_processor.data['year'].unique())
        else:
            available_years = list(range(2000, 2025))

        start_year = st.selectbox(
            "åˆ†æèµ·å§‹å¹´ä»½",
            options=available_years,
            index=0,
            help="é€‰æ‹©GIPSåˆ†æçš„èµ·å§‹å¹´ä»½",
            key="gips_start_year"
        )

        end_year_options = [y for y in available_years if y >= start_year]
        end_year = st.selectbox(
            "åˆ†æç»“æŸå¹´ä»½",
            options=end_year_options,
            index=len(end_year_options) - 1 if end_year_options else 0,
            help="é€‰æ‹©GIPSåˆ†æçš„ç»“æŸå¹´ä»½",
            key="gips_end_year"
        )

    # Run analysis button
    if st.button("ğŸš€ è¿è¡ŒGIPSåˆè§„æ€§åˆ†æ", type="primary", key="gips_run_analysis"):
        try:
            with st.spinner("æ­£åœ¨è¿›è¡ŒGIPSåˆè§„æ€§åˆ†æ..."):
                # Run GIPS compliance analysis
                gips_results = st.session_state.data_processor.compute_gips_compliance_analysis(
                    start_year=start_year,
                    end_year=end_year,
                    benchmark_symbol=benchmark_symbol,
                    firm_name=firm_name,
                    composite_name=composite_name
                )

                # Store results in session state
                st.session_state.gips_results = gips_results

                st.success("âœ… GIPSåˆè§„æ€§åˆ†æå®Œæˆï¼")

        except Exception as e:
            st.error(f"âŒ GIPSåˆ†æå¤±è´¥: {str(e)}")
            st.error("è¯·æ£€æŸ¥æ•°æ®å®Œæ•´æ€§å’Œå‚æ•°è®¾ç½®")
            return

    # Display results if available
    if hasattr(st.session_state, 'gips_results') and st.session_state.gips_results:
        display_gips_results(st.session_state.gips_results)


def display_gips_results(results: Dict):
    """Display GIPS compliance analysis results."""
    st.subheader("ğŸ“Š GIPSåˆè§„æ€§åˆ†æç»“æœ")

    # Main performance metrics with improved styling
    gips_calc = results['gips_calculation']

    # Create a container with custom styling
    st.markdown('<div class="gips-result-container">', unsafe_allow_html=True)

    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.markdown(
            f"""
            <div style="text-align: center; padding: 1rem;">
                <div class="gips-metric-title">æ—¶é—´åŠ æƒæ”¶ç›Šç‡</div>
                <div class="gips-metric-value">{gips_calc['time_weighted_return']:.2%}</div>
                <div style="font-size: 0.75rem; color: #64748b; margin-top: 0.25rem;">GIPSæ ‡å‡†è¦æ±‚çš„æ ¸å¿ƒæŒ‡æ ‡</div>
            </div>
            """,
            unsafe_allow_html=True
        )

    with col2:
        if gips_calc['money_weighted_return'] is not None:
            st.markdown(
                f"""
                <div style="text-align: center; padding: 1rem;">
                    <div class="gips-metric-title">èµ„é‡‘åŠ æƒæ”¶ç›Šç‡</div>
                    <div class="gips-metric-value">{gips_calc['money_weighted_return']:.2%}</div>
                    <div style="font-size: 0.75rem; color: #64748b; margin-top: 0.25rem;">å†…éƒ¨æ”¶ç›Šç‡(IRR)</div>
                </div>
                """,
                unsafe_allow_html=True
            )
        else:
            st.markdown(
                f"""
                <div style="text-align: center; padding: 1rem;">
                    <div class="gips-metric-title">èµ„é‡‘åŠ æƒæ”¶ç›Šç‡</div>
                    <div class="gips-metric-value" style="color: #94a3b8;">N/A</div>
                    <div style="font-size: 0.75rem; color: #64748b; margin-top: 0.25rem;">è®¡ç®—å¤±è´¥æˆ–ä¸é€‚ç”¨</div>
                </div>
                """,
                unsafe_allow_html=True
            )

    with col3:
        compliance_level = gips_calc['compliance_level']
        compliance_config = {
            'full_compliance': {'icon': 'âœ…', 'text': 'Full Compliance', 'class': 'compliance-full'},
            'partial_compliance': {'icon': 'âš ï¸', 'text': 'Partial Compliance', 'class': 'compliance-partial'},
            'non_compliant': {'icon': 'âŒ', 'text': 'Non Compliance', 'class': 'compliance-none'}
        }

        config = compliance_config.get(compliance_level, {'icon': 'â“', 'text': 'Unknown', 'class': 'compliance-none'})

        st.markdown(
            f"""
            <div style="text-align: center; padding: 1rem;">
                <div class="gips-metric-title">åˆè§„æ€§ç­‰çº§</div>
                <div class="gips-compliance-status {config['class']}" style="margin: 0.5rem 0;">
                    {config['icon']} {config['text']}
                </div>
                <div style="font-size: 0.75rem; color: #64748b;">GIPSåˆè§„æ€§è¯„ä¼°</div>
            </div>
            """,
            unsafe_allow_html=True
        )

    with col4:
        period_summary = results['period_summary']
        st.markdown(
            f"""
            <div style="text-align: center; padding: 1rem;">
                <div class="gips-metric-title">åˆ†ææœŸé—´</div>
                <div class="gips-metric-value" style="font-size: 1.25rem; line-height: 1.3;">{period_summary['start_date']} è‡³ {period_summary['end_date']}</div>
                <div style="font-size: 0.75rem; color: #64748b; margin-top: 0.25rem;">GIPSåˆ†ææ—¶é—´èŒƒå›´</div>
            </div>
            """,
            unsafe_allow_html=True
        )

    st.markdown('</div>', unsafe_allow_html=True)

    # Compliance report
    st.subheader("ğŸ“‹ åˆè§„æ€§æŠ¥å‘Š")

    compliance_report = results['compliance_report']

    # Create two columns for the report
    col1, col2 = st.columns(2)

    with col1:
        st.markdown("**åŸºæœ¬ä¿¡æ¯**")
        st.write(f"**å…¬å¸åç§°:** {compliance_report['firm_name']}")
        st.write(f"**æŠ•èµ„ç»„åˆ:** {compliance_report['composite_name']}")
        st.write(f"**åŸºå‡†æŒ‡æ•°:** {compliance_report.get('benchmark_name', 'N/A')}")
        st.write(f"**è®¡ç®—æ–¹æ³•:** {compliance_report['calculation_method']}")

        if 'benchmark_return' in compliance_report:
            st.write(f"**åŸºå‡†æ”¶ç›Šç‡:** {compliance_report['benchmark_return']}")
            st.write(f"**è¶…é¢æ”¶ç›Š:** {compliance_report['excess_return']}")

    with col2:
        st.markdown("**æŠ•èµ„ç»„åˆç»Ÿè®¡**")
        st.write(f"**æŠ•èµ„ç»„åˆæ•°é‡:** {compliance_report['number_of_portfolios']}")
        st.write(f"**æ€»èµ„äº§:** {compliance_report['total_assets']}")
        st.write(f"**æ—¶é—´åŠ æƒæ”¶ç›Šç‡:** {compliance_report['time_weighted_return']}")

        if 'money_weighted_return' in compliance_report:
            st.write(f"**èµ„é‡‘åŠ æƒæ”¶ç›Šç‡:** {compliance_report['money_weighted_return']}")

    # Validation notes
    if gips_calc['validation_notes']:
        st.markdown("**âš ï¸ éªŒè¯è¯´æ˜**")
        for note in gips_calc['validation_notes']:
            st.warning(note)

    # Performance attribution analysis
    st.subheader("ğŸ“ˆ è¡¨ç°å½’å› åˆ†æ")

    attribution = results['attribution_analysis']

    if 'risk_adjusted_metrics' in attribution:
        risk_metrics = attribution['risk_adjusted_metrics']

        col1, col2 = st.columns(2)

        with col1:
            st.markdown("**é£é™©è°ƒæ•´æŒ‡æ ‡**")

            metrics_data = {
                "æŒ‡æ ‡": ["Alpha", "Beta", "å¤æ™®æ¯”ç‡", "ä¿¡æ¯æ¯”ç‡", "è·Ÿè¸ªè¯¯å·®", "è¶…é¢æ”¶ç›Š"],
                "æŠ•èµ„ç»„åˆ": [
                    f"{risk_metrics['alpha']:.4f}",
                    f"{risk_metrics['beta']:.3f}",
                    f"{risk_metrics['portfolio_sharpe']:.3f}",
                    f"{risk_metrics['information_ratio']:.3f}",
                    f"{risk_metrics['tracking_error']:.4f}",
                    f"{risk_metrics['excess_return']:.4f}"
                ],
                "åŸºå‡†": [
                    "0.0000",
                    "1.000",
                    f"{risk_metrics['benchmark_sharpe']:.3f}",
                    "0.000",
                    "0.0000",
                    "0.0000"
                ]
            }

            st.dataframe(pd.DataFrame(metrics_data), use_container_width=True)

        with col2:
            if 'sector_attribution' in attribution:
                st.markdown("**è¡Œä¸šå½’å› åˆ†æ**")

                sector_attr = attribution['sector_attribution']

                attribution_data = {
                    "å½’å› ç»„ä»¶": ["é…ç½®æ•ˆåº”", "é€‰æ‹©æ•ˆåº”", "äº¤äº’æ•ˆåº”", "æ€»å½’å› "],
                    "è´¡çŒ® (%)": [
                        f"{sector_attr['allocation_effect']:.2%}",
                        f"{sector_attr['selection_effect']:.2%}",
                        f"{sector_attr['interaction_effect']:.2%}",
                        f"{sector_attr['total_attribution']:.2%}"
                    ]
                }

                st.dataframe(pd.DataFrame(attribution_data), use_container_width=True)

    # Benchmark validation
    st.subheader("ğŸ¯ åŸºå‡†éªŒè¯")

    benchmark_validation = results['benchmark_validation']

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("**åŸºå‡†é€‚å½“æ€§è¯„ä¼°**")

        if benchmark_validation['is_appropriate']:
            st.success("âœ… åŸºå‡†é€‰æ‹©é€‚å½“")
        else:
            st.error("âŒ åŸºå‡†é€‰æ‹©å¯èƒ½ä¸é€‚å½“")

        if benchmark_validation['validation_notes']:
            st.markdown("**éªŒè¯è¯´æ˜:**")
            for note in benchmark_validation['validation_notes']:
                st.write(f"â€¢ {note}")

    with col2:
        st.markdown("**ç‰¹å¾æ¯”è¾ƒ**")

        portfolio_chars = benchmark_validation['portfolio_characteristics']
        benchmark_chars = benchmark_validation['benchmark_characteristics']

        comparison_data = {
            "ç‰¹å¾": ["èµ„äº§ç±»åˆ«", "åœ°ç†åŒºåŸŸ", "æŠ•èµ„é£æ ¼", "å¸‚å€¼é‡ç‚¹"],
            "æŠ•èµ„ç»„åˆ": [
                portfolio_chars.get('asset_class', 'N/A'),
                portfolio_chars.get('geography', 'N/A'),
                portfolio_chars.get('investment_style', 'N/A'),
                portfolio_chars.get('market_cap_focus', 'N/A')
            ],
            "åŸºå‡†": [
                benchmark_chars.get('asset_class', 'N/A'),
                benchmark_chars.get('geography', 'N/A'),
                benchmark_chars.get('investment_style', 'N/A'),
                benchmark_chars.get('market_cap_focus', 'N/A')
            ]
        }

        st.dataframe(pd.DataFrame(comparison_data), use_container_width=True)

    # GIPS compliance statement
    st.subheader("ğŸ“œ GIPSåˆè§„æ€§å£°æ˜")

    compliance_statement = compliance_report.get('compliance_statement', '')

    if 'claims compliance' in compliance_statement:
        st.success(compliance_statement)
    else:
        st.warning(compliance_statement)

    # Download report option
    st.subheader("ğŸ“¥ æŠ¥å‘Šä¸‹è½½")

    if st.button("ğŸ“„ ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š"):
        # Generate comprehensive report
        report_content = generate_gips_report_content(results)

        st.download_button(
            label="ä¸‹è½½GIPSåˆè§„æ€§æŠ¥å‘Š",
            data=report_content,
            file_name=f"GIPS_Compliance_Report_{compliance_report['composite_name'].replace(' ', '_')}.txt",
            mime="text/plain"
        )


def generate_gips_report_content(results: Dict) -> str:
    """Generate comprehensive GIPS compliance report content."""
    gips_calc = results['gips_calculation']
    compliance_report = results['compliance_report']
    attribution = results['attribution_analysis']
    benchmark_validation = results['benchmark_validation']

    report_lines = [
        "=" * 80,
        "GIPSåˆè§„æ€§åˆ†ææŠ¥å‘Š",
        "Global Investment Performance Standards Compliance Report",
        "=" * 80,
        "",
        f"æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
        "",
        "åŸºæœ¬ä¿¡æ¯",
        "-" * 40,
        f"æŠ•èµ„å…¬å¸: {compliance_report['firm_name']}",
        f"æŠ•èµ„ç»„åˆ: {compliance_report['composite_name']}",
        f"åˆ†ææœŸé—´: {compliance_report['period_start']} è‡³ {compliance_report['period_end']}",
        f"åŸºå‡†æŒ‡æ•°: {compliance_report.get('benchmark_name', 'N/A')}",
        "",
        "è¡¨ç°æŒ‡æ ‡",
        "-" * 40,
        f"æ—¶é—´åŠ æƒæ”¶ç›Šç‡: {compliance_report['time_weighted_return']}",
        f"åŸºå‡†æ”¶ç›Šç‡: {compliance_report.get('benchmark_return', 'N/A')}",
        f"è¶…é¢æ”¶ç›Š: {compliance_report.get('excess_return', 'N/A')}",
        f"è®¡ç®—æ–¹æ³•: {compliance_report['calculation_method']}",
        "",
        "åˆè§„æ€§è¯„ä¼°",
        "-" * 40,
        f"åˆè§„æ€§ç­‰çº§: {gips_calc['compliance_level']}",
        ""
    ]

    if gips_calc['validation_notes']:
        report_lines.extend([
            "éªŒè¯è¯´æ˜:",
            *[f"â€¢ {note}" for note in gips_calc['validation_notes']],
            ""
        ])

    # Add attribution analysis
    if 'risk_adjusted_metrics' in attribution:
        risk_metrics = attribution['risk_adjusted_metrics']
        report_lines.extend([
            "é£é™©è°ƒæ•´æŒ‡æ ‡",
            "-" * 40,
            f"Alpha: {risk_metrics['alpha']:.4f}",
            f"Beta: {risk_metrics['beta']:.3f}",
            f"å¤æ™®æ¯”ç‡: {risk_metrics['portfolio_sharpe']:.3f}",
            f"ä¿¡æ¯æ¯”ç‡: {risk_metrics['information_ratio']:.3f}",
            f"è·Ÿè¸ªè¯¯å·®: {risk_metrics['tracking_error']:.4f}",
            ""
        ])

    # Add compliance statement
    report_lines.extend([
        "GIPSåˆè§„æ€§å£°æ˜",
        "-" * 40,
        compliance_report.get('compliance_statement', ''),
        "",
        "=" * 80,
        "æŠ¥å‘Šç»“æŸ"
    ])

    return "\n".join(report_lines)


if __name__ == "__main__":
    main()
